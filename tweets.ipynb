{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial thoughts \n",
    "### Things done well:\n",
    "- This was my first proper ML project where I achieved a high accuracy compared to my peers\n",
    "- I spent a high amount of time on the project and it really started my passion for ML#\n",
    "- I learnt many skills such as handling different types of data, data processing, trying and improving different models, tf-idf, dimensionality reduction\n",
    "\n",
    "### Improvements:\n",
    "- I spent most of the time trying to increasing my training score as high as possible which is bad as this clearly leads to overfitting\n",
    "- My inital data exploration and subsquent visualisations were poor\n",
    "- I used a bazaar versioning system rather than Jupyter notebooks\n",
    "- I didnt structure my work very well and the explainations were more a stream of thoughts. \n",
    "\n",
    "# We start again\n",
    "\n",
    "## Frame the problem\n",
    "The problem is that we want to be able to take a tweet about a live news story and give a classification as to whether the contents of the message is real or fake. Such a system would be used by a news company to increase their confidence that any tweets they post in their articles are geniune. \n",
    "\n",
    "A current system would require a journalist to go through each individual tweet and make a decision themselves. With this system a list of refined real tweets could be presented to the journalist.\n",
    "\n",
    "It is a supervised offline classification problem where the perfromance is measured by F1 score - the higher the score the more we can trust that a tweet classified as real is a genuine source that can be included in a report\n",
    "\n",
    "I do have my previous system that I could reuse but I won't as in this project I am not looking for high performance but rather a well strucuted notebook with insights and graphs that give reason to my decision making. The only expertise available is my own real world experince of using twitter and seeing how fake tweets are often used by trolls. \n",
    "\n",
    "The minimum perfromance needed to add value is unknown, if we can produce a system that 9/10 gives a correct prediction then this is likely to be useful. \n",
    "\n",
    "The project contains tweet text data for which there are similiar projects avaible that could be looked at for inspiration.\n",
    "\n",
    "\n",
    "## Get the data\n",
    "\n",
    "Data is provided as part of the coursework. The data is real world tweets collected about Hurricane Sandy that hit the US in late 2012\n",
    "\n",
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"data/mediaeval-2015-trainingset.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14277 entries, 263046056240115712 to 442700377860104192\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweetText   14277 non-null  object\n",
      " 1   userId      14277 non-null  int64 \n",
      " 2   imageId(s)  14277 non-null  object\n",
      " 3   username    14277 non-null  object\n",
      " 4   timestamp   14277 non-null  object\n",
      " 5   label       14277 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 780.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight away we can see all of the columns and that it appears we do not have any null vlaues. We have two int columns (tweetId and userId) and then 5 object columns. Both int columns are Id's so there is limited (if any) data inspection we can do here. We could look for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['tweetId', 'userId']\n",
    "obj_attribs = [x for x in data_raw.columns if x not in num_attribs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139189262     16.0\n",
      "834560797     10.0\n",
      "357078809      9.0\n",
      "89221442       8.0\n",
      "2623669827     8.0\n",
      "              ... \n",
      "392302245      2.0\n",
      "464045416      2.0\n",
      "339187255      2.0\n",
      "244344102      2.0\n",
      "31322164       2.0\n",
      "Name: userId, Length: 551, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "users_with_more = data_raw['userId'].value_counts().where(lambda x : x > 1).dropna()\n",
    "print(users_with_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 551 users that appear more than once but will not include 'userId' as a training attribute. This makes sense as this could lead to a model overfitting in the real world. For instance if the model learns that one users tweets are always real and then in practice the system has a fake input from this user it could get passed to the journalist and defeat the goal of the system. However, it could be argued that identifying accounts that are reputable sources or not could be used, this would have to be something to go back to the product owner to discuss. \n",
    "\n",
    "We will also look at tweetId in a similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264736470089216000    2.0\n",
      "263351427320131584    2.0\n",
      "Name: tweetId, dtype: float64\n",
      "[264736470089216000, 263351427320131584]\n"
     ]
    }
   ],
   "source": [
    "tweets_with_more = data_raw['tweetId'].value_counts().where(lambda x : x > 1).dropna()\n",
    "tweetIds = tweets_with_more.keys().tolist()\n",
    "print(tweets_with_more)\n",
    "print(tweetIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  tweetId                                          tweetText  \\\n",
      "2439   264736470089216000  Lower Manhattan's power is gone. Pretty eerie ...   \n",
      "7744   263351427320131584            Ground Zero #Sandy http://t.co/KA1jNv3I   \n",
      "7821   263351427320131584            Ground Zero #Sandy http://t.co/KA1jNv3I   \n",
      "11947  264736470089216000  Lower Manhattan's power is gone. Pretty eerie ...   \n",
      "\n",
      "         userId      imageId(s)      username                       timestamp  \\\n",
      "2439    2675041  sandyB_fake_11         cDima  Sat Nov 03 14:31:07 +0000 2012   \n",
      "7744   15933769  sandyA_real_04  AngelaYvonne  Tue Oct 30 18:47:27 +0000 2012   \n",
      "7821   15933769  sandyA_real_04  AngelaYvonne  Tue Oct 30 18:47:27 +0000 2012   \n",
      "11947   2675041  sandyB_real_54         cDima  Sat Nov 03 14:31:07 +0000 2012   \n",
      "\n",
      "      label  \n",
      "2439   fake  \n",
      "7744   real  \n",
      "7821   real  \n",
      "11947  real  \n"
     ]
    }
   ],
   "source": [
    "print(data_raw[data_raw['tweetId'].isin(tweetIds)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Ground zero' tweets are identical with both having 'real' labels. However, for the 'Lower Manhattan's' tweets one is real and one is fake; the only difference is their imageId(s). We can gain insight here that some of the imageId's actually contain the correct label for the tweet. We can make a feature out of this."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95f1bd513179ec155b64d390ddcc9bcad71f0907251713515d1de287f8f762de"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
